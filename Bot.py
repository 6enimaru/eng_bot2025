import os
import asyncio
import glob
import chromadb
from telegram import Update
from telegram.ext import Application, CommandHandler, MessageHandler, filters, ContextTypes
from sentence_transformers import SentenceTransformer
from llama_cpp import Llama

# ==================== –ù–ê–°–¢–†–û–ô–ö–ò ====================
TELEGRAM_BOT_TOKEN = "8587733755:AAHI-Y-yA-T8G01pC3AdSzNoPIH_GqTK0fc"
MODEL_PATH = r"C:\Users\black\OneDrive\Desktop\LLM_little_models\KviGPT-7b-Chat.i1-Q4_K_M.gguf"
# ===================================================

# –ì–ª–æ–±–∞–ª—å–Ω—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –¥–ª—è RAG —Å–∏—Å—Ç–µ–º—ã
collection = None
embedding_model = None
llm = None

# ==================== –í–ê–® –†–ê–ë–û–ß–ò–ô –ö–û–î ====================

def load_llm_model():
    """
    –ó–∞–≥—Ä—É–∂–∞–µ—Ç –≤–∞—à—É –ª–æ–∫–∞–ª—å–Ω—É—é LLM –º–æ–¥–µ–ª—å
    """
    print("üîÑ –ó–∞–≥—Ä—É–∂–∞—é –ª–æ–∫–∞–ª—å–Ω—É—é LLM...")
    
    try:
        # === –ó–ê–ì–†–£–ó–ö–ê LLM –ú–û–î–ï–õ–ò ===
        llm = Llama(
            model_path=MODEL_PATH,
            n_ctx=4096,  # —Ä–∞–∑–º–µ—Ä –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
            n_threads=8,  # –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ—Ç–æ–∫–æ–≤
            verbose=False  # –≤—ã–≤–æ–¥ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –∑–∞–≥—Ä—É–∑–∫–µ
        )
        
        print("‚úÖ LLM –º–æ–¥–µ–ª—å —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω–∞!")
        return llm
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ LLM: {e}")
        print("üí° –£–±–µ–¥–∏—Ç–µ—Å—å —á—Ç–æ:")
        print("   - –ü—É—Ç—å –∫ –º–æ–¥–µ–ª–∏ –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π")
        print("   - –§–∞–π–ª –º–æ–¥–µ–ª–∏ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç")
        print("   - –£—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞ –±–∏–±–ª–∏–æ—Ç–µ–∫–∞: pip install llama-cpp-python")
        return None

def load_text_files(folder_path="C:/Users/black/OneDrive/Desktop/Grammar_RAG"):
    """
    –ó–∞–≥—Ä—É–∂–∞–µ—Ç –≤—Å–µ —Ç–µ–∫—Å—Ç–æ–≤—ã–µ —Ñ–∞–π–ª—ã –∏–∑ –ø–∞–ø–∫–∏
    """
    print("üìÅ –ó–∞–≥—Ä—É–∂–∞—é —Ç–µ–∫—Å—Ç–æ–≤—ã–µ —Ñ–∞–π–ª—ã...")
    
    # –ò—â–µ–º –≤—Å–µ .txt —Ñ–∞–π–ª—ã –≤ —Ç–µ–∫—É—â–µ–π –ø–∞–ø–∫–µ
    text_files = glob.glob(os.path.join(folder_path, "*.txt"))
    
    if not text_files:
        print("‚ùå –ù–µ –Ω–∞–π–¥–µ–Ω–æ .txt —Ñ–∞–π–ª–æ–≤ –≤ —Ç–µ–∫—É—â–µ–π –ø–∞–ø–∫–µ")
        return []
    
    chunks = []
    
    for file_path in text_files:
        filename = os.path.basename(file_path)
        
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read().strip()
            
            if content:  # –ï—Å–ª–∏ —Ñ–∞–π–ª –Ω–µ –ø—É—Å—Ç–æ–π
                chunk = {
                    "content": content,
                    "metadata": {
                        "source_file": filename,
                        "topic": filename.replace('.txt', ''),  # –ù–∞–∑–≤–∞–Ω–∏–µ —Ñ–∞–π–ª–∞ = —Ç–µ–º–∞
                        "size_chars": len(content),
                        "estimated_tokens": len(content) // 4
                    }
                }
                chunks.append(chunk)
                print(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ: {filename} ({len(content)} —Å–∏–º–≤–æ–ª–æ–≤)")
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è {filename}: {e}")
    
    print(f"\nüéØ –í—Å–µ–≥–æ –∑–∞–≥—Ä—É–∂–µ–Ω–æ —Ç–µ–º: {len(chunks)}")
    return chunks

def show_chunks_info(chunks):
    """
    –ü–æ–∫–∞–∑—ã–≤–∞–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã—Ö —Ç–µ–º–∞—Ö
    """
    print("\nüìä –ó–ê–ì–†–£–ñ–ï–ù–ù–´–ï –¢–ï–ú–´:")
    print("=" * 50)
    
    for i, chunk in enumerate(chunks, 1):
        metadata = chunk["metadata"]
        content_preview = chunk["content"][:80] + "..." if len(chunk["content"]) > 80 else chunk["content"]
        
        print(f"{i}. {metadata['topic']}:")
        print(f"   üìè –†–∞–∑–º–µ—Ä: {metadata['size_chars']} —Å–∏–º–≤–æ–ª–æ–≤")
        print(f"   üî§ –¢–æ–∫–µ–Ω–æ–≤: ~{metadata['estimated_tokens']}")
        print(f"   üìù –ù–∞—á–∞–ª–æ: {content_preview}")
        print()

def create_vector_db(chunks):
    """
    –°–æ–∑–¥–∞–µ—Ç –≤–µ–∫—Ç–æ—Ä–Ω—É—é –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö –∏–∑ —á–∞–Ω–∫–æ–≤
    """
    print("üîÑ –°–æ–∑–¥–∞—é –≤–µ–∫—Ç–æ—Ä–Ω—É—é –ë–î...")
    
    try:
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –º–æ–¥–µ–ª—å –¥–ª—è —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤
        model = SentenceTransformer('all-MiniLM-L6-v2')
        
        # –°–æ–∑–¥–∞–µ–º ChromaDB –∫–ª–∏–µ–Ω—Ç
        client = chromadb.PersistentClient(path="./grammar_db")
        
        # –°–æ–∑–¥–∞–µ–º –∏–ª–∏ –ø–æ–ª—É—á–∞–µ–º –∫–æ–ª–ª–µ–∫—Ü–∏—é
        collection = client.get_or_create_collection(name="grammar_topics")
        
        # –î–æ–±–∞–≤–ª—è–µ–º –¥–æ–∫—É–º–µ–Ω—Ç—ã –≤ –±–∞–∑—É
        documents = []
        metadatas = []
        ids = []
        
        for i, chunk in enumerate(chunks):
            documents.append(chunk["content"])
            metadatas.append(chunk["metadata"])
            ids.append(f"chunk_{i}")
        
        # –°–æ–∑–¥–∞–µ–º —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ –∏ –¥–æ–±–∞–≤–ª—è–µ–º –≤ –±–∞–∑—É
        embeddings = model.encode(documents).tolist()
        collection.add(
            embeddings=embeddings,
            documents=documents,
            metadatas=metadatas,
            ids=ids
        )
        
        print("‚úÖ –í–µ–∫—Ç–æ—Ä–Ω–∞—è –ë–î —Å–æ–∑–¥–∞–Ω–∞!")
        return collection, model
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è –≤–µ–∫—Ç–æ—Ä–Ω–æ–π –ë–î: {e}")
        return None, None

def ask_question_with_llm(question):
    """
    –ó–∞–¥–∞–µ—Ç –≤–æ–ø—Ä–æ—Å RAG —Å–∏—Å—Ç–µ–º–µ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –≤–∞—à–µ–π LLM
    """
    global collection, embedding_model, llm
    
    if collection is None:
        return "‚ùå –í–µ–∫—Ç–æ—Ä–Ω–∞—è –ë–î –Ω–µ —Å–æ–∑–¥–∞–Ω–∞"
    
    if llm is None:
        return "‚ùå LLM –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω–∞"
    
    print(f"\n‚ùì –í–æ–ø—Ä–æ—Å —Å—Ç—É–¥–µ–Ω—Ç–∞: {question}")
    print("ü§î –ò—â—É –º–∞—Ç–µ—Ä–∏–∞–ª—ã...")
    
    # –°–æ–∑–¥–∞–µ–º —ç–º–±–µ–¥–¥–∏–Ω–≥ –¥–ª—è –≤–æ–ø—Ä–æ—Å–∞
    question_embedding = embedding_model.encode([question]).tolist()
    
    # –ò—â–µ–º –ø–æ—Ö–æ–∂–∏–µ —á–∞–Ω–∫–∏
    results = collection.query(
        query_embeddings=question_embedding,
        n_results=3
    )
    
    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –Ω–∞–π–¥–µ–Ω–Ω—ã–µ –º–∞—Ç–µ—Ä–∏–∞–ª—ã (–≤ –∫–æ–Ω—Å–æ–ª—å)
    print("üìö –ù–∞–π–¥–µ–Ω–Ω—ã–µ –º–∞—Ç–µ—Ä–∏–∞–ª—ã:")
    for i, (doc, metadata) in enumerate(zip(results['documents'][0], results['metadatas'][0])):
        print(f"{i+1}. –¢–µ–º–∞: {metadata['topic']}")
        print(f"   –°–æ–¥–µ—Ä–∂–∞–Ω–∏–µ: {doc[:100]}...")
    
    # === –ü–û–î–ì–û–¢–û–í–ö–ê –ü–†–û–ú–ü–¢–ê –î–õ–Ø LLM ===
    context = ""
    for doc, metadata in zip(results['documents'][0], results['metadatas'][0]):
        context += f"–¢–ï–ú–ê: {metadata['topic']}\n{doc}\n\n"
    
    prompt = f"""–¢—ã - —É—á–∏—Ç–µ–ª—å –∞–Ω–≥–ª–∏–π—Å–∫–æ–≥–æ —è–∑—ã–∫–∞. –û—Ç–≤–µ—Ç—å –Ω–∞ –≤–æ–ø—Ä–æ—Å —Å—Ç—É–¥–µ–Ω—Ç–∞, –∏—Å–ø–æ–ª—å–∑—É—è –¢–û–õ–¨–ö–û –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã–µ –º–∞—Ç–µ—Ä–∏–∞–ª—ã.

–ú–ê–¢–ï–†–ò–ê–õ–´ –î–õ–Ø –û–¢–í–ï–¢–ê:
{context}

–í–û–ü–†–û–° –°–¢–£–î–ï–ù–¢–ê: {question}

–ò–ù–°–¢–†–£–ö–¶–ò–ò:
1. –û—Ç–≤–µ—Ç—å —á–µ—Ç–∫–æ –∏ –ø–æ–Ω—è—Ç–Ω–æ –Ω–∞ —Ä—É—Å—Å–∫–æ–º –∏–ª–∏ –∞–Ω–≥–ª–∏–π—Å–∫–æ–º (–≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –≤–æ–ø—Ä–æ—Å–∞)
2. –ò—Å–ø–æ–ª—å–∑—É–π —Ç–æ–ª—å–∫–æ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏–∑ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã—Ö –º–∞—Ç–µ—Ä–∏–∞–ª–æ–≤
3. –ï—Å–ª–∏ –≤ –º–∞—Ç–µ—Ä–∏–∞–ª–∞—Ö –Ω–µ—Ç –æ—Ç–≤–µ—Ç–∞ - –≤–µ–∂–ª–∏–≤–æ —Å–∫–∞–∂–∏ –æ–± —ç—Ç–æ–º
4. –ë—É–¥—å —Ç–µ—Ä–ø–µ–ª–∏–≤—ã–º –∏ helpful —É—á–∏—Ç–µ–ª–µ–º
5. –ü—Ä–∏–≤–æ–¥–∏ –ø—Ä–∏–º–µ—Ä—ã –∏–∑ –º–∞—Ç–µ—Ä–∏–∞–ª–æ–≤

–û–¢–í–ï–¢ –£–ß–ò–¢–ï–õ–Ø:"""
    
    # === –í–´–ó–û–í –í–ê–®–ï–ô LLM –ú–û–î–ï–õ–ò ===
    print("\nüß† –ì–µ–Ω–µ—Ä–∏—Ä—É—é –æ—Ç–≤–µ—Ç...")
    
    try:
        response = llm(
            prompt,
            max_tokens=500,  # –£–≤–µ–ª–∏—á–∏–º –¥–ª—è –±–æ–ª–µ–µ –ø–æ–ª–Ω—ã—Ö –æ—Ç–≤–µ—Ç–æ–≤
            temperature=0.3,  # –ü–æ–Ω–∏–∑–∏–º –¥–ª—è –±–æ–ª–µ–µ —Ç–æ—á–Ω—ã—Ö –æ—Ç–≤–µ—Ç–æ–≤
            echo=False,
            stop=["–°—Ç—É–¥–µ–Ω—Ç:", "–£—á–∏—Ç–µ–ª—å:", "–í–æ–ø—Ä–æ—Å:"]  # –°—Ç–æ–ø-—Å–ª–æ–≤–∞ –¥–ª—è —á–∏—Å—Ç–æ—Ç—ã –æ—Ç–≤–µ—Ç–∞
        )
        
        answer = response['choices'][0]['text'].strip()
        print(f"\nüí° –û–¢–í–ï–¢ –£–ß–ò–¢–ï–õ–Ø: {answer}")
        return answer
        
    except Exception as e:
        error_msg = f"‚ùå –û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç–≤–µ—Ç–∞: {e}"
        print(error_msg)
        return error_msg

def initialize_rag_system():
    """
    –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ—Ç –≤—Å—é RAG —Å–∏—Å—Ç–µ–º—É
    """
    global collection, embedding_model, llm
    
    print("üéØ –ò–ù–ò–¶–ò–ê–õ–ò–ó–ê–¶–ò–Ø RAG –°–ò–°–¢–ï–ú–´ –î–õ–Ø TELEGRAM")
    print("=" * 50)
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º LLM –º–æ–¥–µ–ª—å
    llm = load_llm_model()
    if llm is None:
        return False
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º —Ç–µ–∫—Å—Ç–æ–≤—ã–µ —Ñ–∞–π–ª—ã —Å —Ç–µ–º–∞–º–∏
    chunks = load_text_files()
    
    if not chunks:
        print("‚ùå –ù–µ—á–µ–≥–æ –∑–∞–≥—Ä—É–∂–∞—Ç—å. –î–æ–±–∞–≤—å—Ç–µ .txt —Ñ–∞–π–ª—ã –≤ –ø–∞–ø–∫—É.")
        return False
    
    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Ç–µ–º–∞—Ö
    show_chunks_info(chunks)
    
    # –°–æ–∑–¥–∞–µ–º –≤–µ–∫—Ç–æ—Ä–Ω—É—é –ë–î
    collection, embedding_model = create_vector_db(chunks)
    
    if collection and embedding_model:
        print(f"\n‚úÖ RAG –°–ò–°–¢–ï–ú–ê –ì–û–¢–û–í–ê! –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(chunks)} —Ç–µ–º")
        return True
    
    return False

# ==================== TELEGRAM –ë–û–¢ ====================

async def start_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ –∫–æ–º–∞–Ω–¥—ã /start"""
    user = update.effective_user
    welcome_text = f"""
üëã –ü—Ä–∏–≤–µ—Ç, {user.first_name}!

–Ø - —É–º–Ω—ã–π —É—á–∏—Ç–µ–ª—å –∞–Ω–≥–ª–∏–π—Å–∫–æ–≥–æ! üìö

üéØ **–ß—Ç–æ —è —É–º–µ—é:**
‚Ä¢ –û–±—ä—è—Å–Ω—è—Ç—å –≥—Ä–∞–º–º–∞—Ç–∏–∫—É –∞–Ω–≥–ª–∏–π—Å–∫–æ–≥–æ
‚Ä¢ –û—Ç–≤–µ—á–∞—Ç—å –Ω–∞ –≤–æ–ø—Ä–æ—Å—ã –ø–æ —É—á–µ–±–Ω—ã–º –º–∞—Ç–µ—Ä–∏–∞–ª–∞–º
‚Ä¢ –ü–æ–º–æ–≥–∞—Ç—å —Å –ø–æ–Ω–∏–º–∞–Ω–∏–µ–º –≤—Ä–µ–º–µ–Ω –∏ –∫–æ–Ω—Å—Ç—Ä—É–∫—Ü–∏–π

üí° **–ü—Ä–∏–º–µ—Ä—ã –≤–æ–ø—Ä–æ—Å–æ–≤:**
‚Ä¢ "–û–±—ä—è—Å–Ω–∏ Present Perfect"
‚Ä¢ "–í —á–µ–º —Ä–∞–∑–Ω–∏—Ü–∞ –º–µ–∂–¥—É Past Simple –∏ Present Perfect?"
‚Ä¢ "–ß—Ç–æ —Ç–∞–∫–æ–µ —É—Å–ª–æ–≤–Ω—ã–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è?"
‚Ä¢ "–ö–∞–∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –º–æ–¥–∞–ª—å–Ω—ã–µ –≥–ª–∞–≥–æ–ª—ã?"

–ü—Ä–æ—Å—Ç–æ –∑–∞–¥–∞–π –≤–æ–ø—Ä–æ—Å - –∏ —è –Ω–∞–π–¥—É –æ—Ç–≤–µ—Ç –≤ —É—á–µ–±–Ω—ã—Ö –º–∞—Ç–µ—Ä–∏–∞–ª–∞—Ö! üéì
    """
    await update.message.reply_text(welcome_text)

async def help_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ –∫–æ–º–∞–Ω–¥—ã /help"""
    help_text = """
üìñ **–ü–æ–º–æ—â—å –ø–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é –±–æ—Ç–∞:**

**–ö–∞–∫ –∑–∞–¥–∞–≤–∞—Ç—å –≤–æ–ø—Ä–æ—Å—ã:**
–ü—Ä–æ—Å—Ç–æ –Ω–∞–ø–∏—à–∏—Ç–µ –≤–æ–ø—Ä–æ—Å –Ω–∞ —Ä—É—Å—Å–∫–æ–º –∏–ª–∏ –∞–Ω–≥–ª–∏–π—Å–∫–æ–º –æ –≥—Ä–∞–º–º–∞—Ç–∏–∫–µ, –≤—Ä–µ–º–µ–Ω–∞—Ö, –∏–ª–∏ –ª—é–±—ã—Ö —Ç–µ–º–∞—Ö –∞–Ω–≥–ª–∏–π—Å–∫–æ–≥–æ —è–∑—ã–∫–∞.

**–ü—Ä–∏–º–µ—Ä—ã:**
‚Ä¢ "–û–±—ä—è—Å–Ω–∏ Present Perfect"
‚Ä¢ "–†–∞–∑–Ω–∏—Ü–∞ –º–µ–∂–¥—É Past Simple –∏ Present Perfect"
‚Ä¢ "–ß—Ç–æ —Ç–∞–∫–æ–µ reported speech?"
‚Ä¢ "–ö–∞–∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –∞—Ä—Ç–∏–∫–ª–∏ a/an/the?"

**–ö–æ–º–∞–Ω–¥—ã:**
/start - –Ω–∞—á–∞—Ç—å —Ä–∞–±–æ—Ç—É
/help - –ø–æ–∫–∞–∑–∞—Ç—å —ç—Ç—É —Å–ø—Ä–∞–≤–∫—É
/status - —Å—Ç–∞—Ç—É—Å —Å–∏—Å—Ç–µ–º—ã

–ù–µ —Å—Ç–µ—Å–Ω—è–π—Ç–µ—Å—å –∑–∞–¥–∞–≤–∞—Ç—å –≤–æ–ø—Ä–æ—Å—ã! –Ø –∑–¥–µ—Å—å, —á—Ç–æ–±—ã –ø–æ–º–æ—á—å! üòä
    """
    await update.message.reply_text(help_text)

async def status_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ –∫–æ–º–∞–Ω–¥—ã /status"""
    if llm and collection:
        status_text = "‚úÖ –°–∏—Å—Ç–µ–º–∞ –ø–æ–ª–Ω–æ—Å—Ç—å—é –≥–æ—Ç–æ–≤–∞ –∫ —Ä–∞–±–æ—Ç–µ!\n\nü§ñ LLM –º–æ–¥–µ–ª—å: –∑–∞–≥—Ä—É–∂–µ–Ω–∞\nüóÑÔ∏è –í–µ–∫—Ç–æ—Ä–Ω–∞—è –ë–î: —Å–æ–∑–¥–∞–Ω–∞\nüìö –ú–∞—Ç–µ—Ä–∏–∞–ª—ã: –¥–æ—Å—Ç—É–ø–Ω—ã"
    else:
        status_text = "üîÑ –°–∏—Å—Ç–µ–º–∞ –∑–∞–≥—Ä—É–∂–∞–µ—Ç—Å—è –∏–ª–∏ –≤–æ–∑–Ω–∏–∫–ª–∏ –æ—à–∏–±–∫–∏"
    
    await update.message.reply_text(status_text)

async def handle_message(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π"""
    user_message = update.message.text.strip()
    
    if not user_message:
        await update.message.reply_text("üìù –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –≤–≤–µ–¥–∏—Ç–µ –≤–æ–ø—Ä–æ—Å")
        return
    
    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º, —á—Ç–æ –±–æ—Ç –ø–µ—á–∞—Ç–∞–µ—Ç
    await context.bot.send_chat_action(chat_id=update.effective_chat.id, action="typing")
    
    # –ü–æ–ª—É—á–∞–µ–º –æ—Ç–≤–µ—Ç –æ—Ç RAG —Å–∏—Å—Ç–µ–º—ã
    try:
        # –ó–∞–ø—É—Å–∫–∞–µ–º –≤ –æ—Ç–¥–µ–ª—å–Ω–æ–º –ø–æ—Ç–æ–∫–µ, —á—Ç–æ–±—ã –Ω–µ –±–ª–æ–∫–∏—Ä–æ–≤–∞—Ç—å Telegram
        response = await asyncio.get_event_loop().run_in_executor(
            None, ask_question_with_llm, user_message
        )
        
        # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –æ—Ç–≤–µ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é
        await update.message.reply_text(response)
        
    except Exception as e:
        error_msg = f"‚ùå –ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –≤–æ–ø—Ä–æ—Å–∞: {str(e)}"
        print(error_msg)
        await update.message.reply_text(error_msg)

async def error_handler(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ –æ—à–∏–±–æ–∫"""
    print(f"‚ùå –û—à–∏–±–∫–∞ Telegram –±–æ—Ç–∞: {context.error}")

def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –∑–∞–ø—É—Å–∫–∞"""
    print("üöÄ –ó–ê–ü–£–°–ö TELEGRAM RAG –ë–û–¢–ê...")
    
    # –§–∏–∫—Å –¥–ª—è Windows
    if os.name == 'nt':
        asyncio.set_event_loop_policy(asyncio.WindowsSelectorEventLoopPolicy())
    
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º RAG —Å–∏—Å—Ç–µ–º—É
    if not initialize_rag_system():
        print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å RAG —Å–∏—Å—Ç–µ–º—É. –ë–æ—Ç –Ω–µ –∑–∞–ø—É—â–µ–Ω.")
        return
    
    try:
        # –°–æ–∑–¥–∞–µ–º Telegram –±–æ—Ç–∞
        app = Application.builder().token(TELEGRAM_BOT_TOKEN).build()
        
        # –î–æ–±–∞–≤–ª—è–µ–º –æ–±—Ä–∞–±–æ—Ç—á–∏–∫–∏
        app.add_handler(CommandHandler("start", start_command))
        app.add_handler(CommandHandler("help", help_command))
        app.add_handler(CommandHandler("status", status_command))
        app.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, handle_message))
        app.add_error_handler(error_handler)
        
        # –ó–∞–ø—É—Å–∫–∞–µ–º –±–æ—Ç–∞
        print("\n‚úÖ TELEGRAM –ë–û–¢ –ó–ê–ü–£–©–ï–ù!")
        print("üì± –ù–∞–ø–∏—à–∏—Ç–µ –≤–∞—à–µ–º—É –±–æ—Ç—É –≤ Telegram")
        print("‚èπÔ∏è  –î–ª—è –æ—Å—Ç–∞–Ω–æ–≤–∫–∏ –Ω–∞–∂–º–∏—Ç–µ Ctrl+C")
        print("\n" + "=" * 50)
        
        app.run_polling()
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–ø—É—Å–∫–∞ Telegram –±–æ—Ç–∞: {e}")

if __name__ == "__main__":
    main()